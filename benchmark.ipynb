{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform inputs to pandas dataframe\n",
    "\n",
    "## Stock Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPY Price & Volume\n",
    "#### https://uk.finance.yahoo.com/quote/SPY/history\n",
    "benchmark_df = pd.read_csv('./inputFeatures/stockIndex/SPY.csv',\n",
    "    index_col=[\"Date\"], \n",
    "    usecols=[\"Date\", \"Open\", \"High\", \"Low\", \"SPYClose\", \"Volume\"],\n",
    "    parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "from time import time\n",
    "\n",
    "def get_last_days(number_of_days, x):\n",
    "    return np.delete(x, np.s_[:-number_of_days], 1)\n",
    "\n",
    "SEQ_LEN = 63\n",
    "FUTURE_PERIOD_PREDICT = 1\n",
    "\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def preprocess_df(df):\n",
    "    # 'RepoRate', 'ReverseRepoRate', 'Repo', 'ReverseRepo', 'USDGBP', 'USDEUR', 'USDJPY', 'M1Supply', 'EmploymentRate', 'InflationRate', 'GDP', 'PCR', 'UMCSENT', 'Confidence', 'EFFR'\n",
    "    df = df.drop(columns=['future'])\n",
    "\n",
    "    output_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in ['SPYClose', 'Open', 'High', 'Low', 'Volume'] :\n",
    "            column_name = f'{col}DayChange'\n",
    "            output_df = pd.concat([output_df, df[col].pct_change(fill_method='ffill').rename(column_name)], axis=1)\n",
    "            output_df.dropna(inplace=True)\n",
    "        elif col == 'target':\n",
    "            output_df[col] = df[col]\n",
    "\n",
    "        if col not in ['SPYClose', 'target']:\n",
    "            output_df.dropna(inplace=True)\n",
    "            output_df[column_name] = preprocessing.scale(output_df[column_name].values)\n",
    "            output_df[column_name] = output_df[column_name].clip(-3, 3) / 3\n",
    "\n",
    "    output_df.dropna(inplace=True)\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "    \n",
    "    for i in output_df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 21 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "            \n",
    "    np.random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "    ups = []\n",
    "    downs = []\n",
    "\n",
    "    for sequence, target in sequential_data:    \n",
    "        if target == 0:\n",
    "            downs.append([sequence, target])\n",
    "        elif target == 1:\n",
    "            ups.append([sequence, target])\n",
    "    np.random.shuffle(ups)\n",
    "    np.random.shuffle(downs)\n",
    "\n",
    "    ## Get the value of the array with the smallest length\n",
    "    ## So we can ensure the training process is unbiased\n",
    "    ## As there will be 50:50 of up days and down days.\n",
    "    ## The model has to LEARN rather than REMEMBER\n",
    "    lower = min(len(ups), len(downs))\n",
    "\n",
    "    ups = ups[:lower]\n",
    "    downs = downs[:lower]\n",
    "\n",
    "    sequential_data = ups + downs\n",
    "\n",
    "    np.random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for sequence, target in sequential_data:\n",
    "        X.append(sequence)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply preprocessing, arrange data (training, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for next day's closing price\n",
    "benchmark_df['future'] = benchmark_df['SPYClose'].shift(-1)\n",
    "# Add column to signify if next day's closing price is up (1) or down (0) using classify\n",
    "# function defined above\n",
    "benchmark_df['target'] = list(map(classify, benchmark_df['SPYClose'], benchmark_df['future']))\n",
    "\n",
    "\n",
    "times = sorted(benchmark_df.index.values)\n",
    "last_20pct = sorted(benchmark_df.index.values)[-int(0.2*len(times))]  # get the last 20% of the times\n",
    "\n",
    "## Split in sample / out of sample\n",
    "validation_df = benchmark_df[(benchmark_df.index >= last_20pct)]  # make the validation data where the index is in the last 20%\n",
    "training_df = benchmark_df[(benchmark_df.index < last_20pct)]  # now the benchmark_df is all the data up to the last 20%\n",
    "\n",
    "train_x, train_y = preprocess_df(training_df)\n",
    "validation_x, validation_y = preprocess_df(validation_df)\n",
    "\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {np.count_nonzero(train_y == 0)}, buys: {np.count_nonzero(train_y == 1)}\")\n",
    "print(f\"VALIDATION Dont buys: {np.count_nonzero(validation_y == 0)}, buys: {np.count_nonzero(validation_y == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, BatchNormalization, Dense, Conv1D, MaxPooling1D, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_two_days = get_last_days(2, train_x) # 2 days\n",
    "train_x_week = get_last_days(5, train_x) # 1 week\n",
    "train_x_two_weeks = get_last_days(10, train_x) # 2 weeks\n",
    "train_x_month = get_last_days(21, train_x) # 1 month\n",
    "train_x_two_months = get_last_days(42, train_x) # 2 months\n",
    "train_x # 1 quarter\n",
    "\n",
    "validation_x_two_days = get_last_days(2, validation_x) # 2 days\n",
    "validation_x_week = get_last_days(5, validation_x) # 1 week\n",
    "validation_x_two_weeks = get_last_days(10, validation_x) # 2 weeks\n",
    "validation_x_month = get_last_days(21, validation_x) # 1 month\n",
    "validation_x_two_months = get_last_days(42, validation_x) # 1 month\n",
    "validation_x # 1 quarter\n",
    "\n",
    "def benchmark_model(name, time_at_start, train_inputs, validation_inputs):\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 50\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train_inputs.shape[1:])))\n",
    "        \n",
    "    model.add(Conv1D(32, 2, padding='same'))\n",
    "    model.add(Conv1D(32, 2, padding='same'))\n",
    "\n",
    "    model.add(LSTM(16))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                    optimizer=opt,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=f'benchmark_logs-{time_at_start}/{name}')\n",
    "\n",
    "    checkpoint_filepath = f\"benchmark_models-{time_at_start}/\" + name + \"-{epoch:02d}-{val_accuracy:.3f}.hd5\"\n",
    "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', baseline=0.5, patience=12)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_inputs, train_y,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(validation_inputs, validation_y),\n",
    "        callbacks=[tensorboard, checkpoint, early_stopping]\n",
    "    )\n",
    "\n",
    "\n",
    "def benchmark():\n",
    "    time_at_start = int(time())\n",
    "\n",
    "    for training_set in ['two_days', 'week', 'two_weeks', 'month', 'two_months', 'quarter']:\n",
    "        if training_set == 'two_days':\n",
    "            training_set_to_use = train_x_two_days\n",
    "            validation_set_to_use = validation_x_two_days\n",
    "        elif training_set == 'week':\n",
    "            training_set_to_use = train_x_week\n",
    "            validation_set_to_use = validation_x_week\n",
    "        elif training_set == 'two_weeks':\n",
    "            training_set_to_use = train_x_two_weeks\n",
    "            validation_set_to_use = validation_x_two_weeks\n",
    "        elif training_set == 'month':\n",
    "            training_set_to_use = train_x_month\n",
    "            validation_set_to_use = validation_x_month\n",
    "        elif training_set == 'two_months':\n",
    "            training_set_to_use = train_x_two_months\n",
    "            validation_set_to_use = validation_x_two_months\n",
    "        elif training_set == 'quarter':\n",
    "            training_set_to_use = train_x\n",
    "            validation_set_to_use = validation_x\n",
    "\n",
    "        name = f\"{training_set}-{int(time())}\"\n",
    "        benchmark_model(name, time_at_start, training_set_to_use, validation_set_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
