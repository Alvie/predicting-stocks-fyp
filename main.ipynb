{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform inputs to pandas dataframe\n",
    "\n",
    "## Stock Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPY Price & Volume\n",
    "#### https://uk.finance.yahoo.com/quote/SPY/history\n",
    "spy_df = pd.read_csv('./inputFeatures/stockIndex/SPY.csv',\n",
    "    index_col=[\"Date\"], \n",
    "    usecols=[\"Date\", \"SPYClose\", \"Volume\"],\n",
    "    parse_dates=[\"Date\"])\n",
    "\n",
    "### VIX (Volatility Index)\n",
    "#### https://uk.finance.yahoo.com/quote/%5EVIX/history\n",
    "vix_df = pd.read_csv('./inputFeatures/stockIndex/VIX.csv',\n",
    "    index_col=[\"Date\"], \n",
    "    usecols=[\"Date\", \"VIXClose\"],\n",
    "    parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Money availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### M1 Money Supply\n",
    "#### Board of Governors of the Federal Reserve System (US), M1 [WM1NS],\n",
    "#### retrieved from FRED, Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/WM1NS, March 31, 2022.\n",
    "m1_df = pd.read_csv('./inputFeatures/moneyAvailability/WM1NS.csv',\n",
    "    index_col=[\"Date\"],\n",
    "    parse_dates=[\"Date\"])\n",
    "\n",
    "### Employment Rate\n",
    "#### Organization for Economic Co-operation and Development,\n",
    "#### Employment Rate: Aged 15-64: All Persons for the United States\n",
    "#### [LREM64TTUSM156S], retrieved from FRED,\n",
    "#### Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/LREM64TTUSM156S, March 31, 2022.\n",
    "employment_df = pd.read_csv('./inputFeatures/moneyAvailability/EmploymentRate.csv',\n",
    "    index_col=[\"Date\"],\n",
    "    parse_dates=[\"Date\"])\n",
    "\n",
    "### Inflation Rate\n",
    "## data.bls.gov\n",
    "inflation_df = pd.read_csv('./inputFeatures/moneyAvailability/InflationRate.csv',\n",
    "    index_col=[\"Date\"],\n",
    "    parse_dates=[\"Date\"])\n",
    "\n",
    "### GDP Rate\n",
    "#### U.S. Bureau of Economic Analysis, Gross Domestic Product [GDP], retrieved from FRED,\n",
    "#### Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/GDP, March 31, 2022.\n",
    "gdp_df = pd.read_csv('./inputFeatures/moneyAvailability/GDP.csv',\n",
    "    index_col=[\"Date\"],\n",
    "    parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put Call Ratio\n",
    "#### https://www.alphalerts.com/live-historical-equity-pcr/\n",
    "pcr_df = pd.read_csv('./inputFeatures/sentimentIndicators/PCR.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "### Consumer Sentiment\n",
    "#### Surveys of Consumers, University of Michigan: Consumer Sentiment Â© [UMCSENT]\n",
    "#### retrieved from FRED, Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/UMCSENT, March 31, 2022.\n",
    "umcsent_df = pd.read_csv('./inputFeatures/sentimentIndicators/UMCSENT.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "### Consumer Confidence\n",
    "#### Organization for Economic Co-operation and Development, Organization for Economic Co-operation and Development:\n",
    "#### Main Economic Indicators (database),http://dx.doi.org/10.1787/data-00052-en\n",
    "#### retrieved from FRED, Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/CSCICP03USM665S, March 31, 2022.\n",
    "confidence_df = pd.read_csv('./inputFeatures/sentimentIndicators/CSCICP03USM665S.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Treasury Yield Rates\n",
    "#### https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve\n",
    "treasury_df = pd.read_csv('./inputFeatures/portfolioAllocations/treasury/daily-treasury-rates.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "### Effective Funds Rate\n",
    "#### Federal Reserve Bank of New York, Effective Federal Funds Rate [EFFR],\n",
    "#### retrieved from FRED, Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/EFFR, March 31, 2022.\n",
    "effr_df = pd.read_csv('./inputFeatures/portfolioAllocations/treasury/EFFR.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "### Accepted Repurchase Agreements (Repo) by the Federal Reserve\n",
    "#### Federal Reserve Bank of New York, Overnight Repurchase Agreements:\n",
    "#### Treasury Securities Purchased by the Federal Reserve in the Temporary Open Market Operations [RPONTSYD],\n",
    "#### retrieved from FRED, Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/RPONTSYD, March 31, 2022.\n",
    "#### https://www.newyorkfed.org/markets/desk-operations/repo\n",
    "repo_df = pd.read_csv('./inputFeatures/portfolioAllocations/treasury/REPO.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "### Accepted Reverse Repurchase Agreements (Reverse Repo) by the Federal Reserve\n",
    "#### Federal Reserve Bank of New York, Overnight Reverse Repurchase Agreements:\n",
    "#### Treasury Securities Sold by the Federal Reserve in the Temporary Open Market Operations [RRPONTSYD],\n",
    "#### retrieved from FRED, Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/RRPONTSYD, March 31, 2022.\n",
    "reverse_repo_df = pd.read_csv('./inputFeatures/portfolioAllocations/treasury/REVERSEREPO.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "### Gold Rate\n",
    "#### https://www.lbma.org.uk/prices-and-data/precious-metal-prices#/table\n",
    "gold_df = pd.read_csv('./inputFeatures/portfolioAllocations/commodities/gold.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "### JPY Rate\n",
    "#### Board of Governors of the Federal Reserve System (US),\n",
    "#### Japanese Yen to U.S. Dollar Spot Exchange Rate [DEXJPUS],\n",
    "#### retrieved from FRED, Federal Reserve Bank of St. Louis;\n",
    "#### https://fred.stlouisfed.org/series/DEXJPUS, April 3, 2022.\n",
    "jpy_df = pd.read_csv('./inputFeatures/portfolioAllocations/currency/JPY.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "         \n",
    "eur_df = pd.read_csv('./inputFeatures/portfolioAllocations/currency/EUR.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "gbp_df = pd.read_csv('./inputFeatures/portfolioAllocations/currency/GBP.csv',\n",
    "    index_col=['Date'],\n",
    "    parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Necessary functions\n",
    "def get_most_recent_value(date, lookup_df, column_name):\n",
    "    most_recent_date = [index for index in lookup_df.index if index <= date][-1]\n",
    "    return lookup_df[column_name].loc[most_recent_date]\n",
    "\n",
    "def calculate_percentage_change(index, number_of_days, lookup_df, column_name):\n",
    "    if (index + number_of_days < 0):\n",
    "        return None\n",
    "    if (index == combined_df.shape[0] - 1):\n",
    "        return None\n",
    "    final_value = lookup_df.iloc[max(index, index + number_of_days)][column_name]\n",
    "    starting_value = lookup_df.iloc[min(index, index + number_of_days)][column_name]\n",
    "    return (final_value - starting_value) / abs(starting_value) * 100\n",
    "\n",
    "dfs_to_combine = [\n",
    "    vix_df,\n",
    "    m1_df,\n",
    "    employment_df,\n",
    "    inflation_df,\n",
    "    gdp_df,\n",
    "    pcr_df,\n",
    "    umcsent_df,\n",
    "    confidence_df,\n",
    "    treasury_df,\n",
    "    effr_df,\n",
    "    repo_df,\n",
    "    reverse_repo_df,\n",
    "    gold_df,\n",
    "    jpy_df,\n",
    "    eur_df,\n",
    "    gbp_df]\n",
    "\n",
    "combined_df = spy_df\n",
    "combined_df = combined_df.join([df for df in dfs_to_combine])\n",
    "\n",
    "combined_df = combined_df[~combined_df.index.duplicated(keep='first')]\n",
    "\n",
    "for date in combined_df.index:\n",
    "    integer_location = combined_df.index.get_loc(date)\n",
    "\n",
    "    ### Fill in any gaps that may remain as a result of mismatched reported dates\n",
    "    ### This will repeat values in dates where there are extended periods without values\n",
    "    ### e.g. quarterly, monthly, weekly values\n",
    "    combined_df.at[date, 'M1Supply'] = get_most_recent_value(date, m1_df, 'M1Supply')\n",
    "    combined_df.at[date, 'EmploymentRate'] = get_most_recent_value(date, employment_df, 'EmploymentRate')\n",
    "    combined_df.at[date, 'InflationRate'] = get_most_recent_value(date, inflation_df, 'InflationRate')\n",
    "    combined_df.at[date, 'GDP'] = get_most_recent_value(date, gdp_df, 'GDP')\n",
    "    combined_df.at[date, 'UMCSENT'] = get_most_recent_value(date, umcsent_df, 'UMCSENT')\n",
    "    combined_df.at[date, 'Confidence'] = get_most_recent_value(date, confidence_df, 'Confidence')\n",
    "\n",
    "    ### Fill in gaps in treasury returns (due to bank holidays but market open)\n",
    "    ### by averaging the surrounding values if available\n",
    "    single_missing_value_columns = [\n",
    "        '1Mo', '3Mo', '1Yr', '2Yr', '5Yr', '10Yr', '20Yr', '30Yr',\n",
    "        'Repo', 'RepoRate', 'ReverseRepo', 'ReverseRepoRate', 'Price'\n",
    "    ]\n",
    "\n",
    "    for single_missing_value_column in single_missing_value_columns:\n",
    "        if (np.isnan(combined_df.at[date, single_missing_value_column])):\n",
    "            surrounding_values = combined_df.loc[\n",
    "                [combined_df.index[integer_location - 1], combined_df.index[integer_location + 1]],\n",
    "                single_missing_value_column\n",
    "            ].values\n",
    "            \n",
    "            if not (np.isnan(surrounding_values).any()):\n",
    "                combined_df.at[date, single_missing_value_column] = np.mean(surrounding_values)\n",
    "\n",
    "    combined_df['Repo'] = combined_df['Repo'].fillna(0.001)\n",
    "    combined_df['RepoRate'] = combined_df['RepoRate'].fillna(0.001)\n",
    "    combined_df['ReverseRepo'] = combined_df['ReverseRepo'].fillna(0.001)\n",
    "    combined_df['ReverseRepoRate'] = combined_df['ReverseRepoRate'].fillna(0.001)\n",
    "\n",
    "combined_df[combined_df < 0.001] = 0.001\n",
    "# combined_df.to_excel(\"./inputFeatures/combined.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "from time import time\n",
    "\n",
    "SEQ_LEN = 63\n",
    "FUTURE_PERIOD_PREDICT = 1\n",
    "\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def preprocess_df(df):\n",
    "    # 'RepoRate', 'ReverseRepoRate', 'Repo', 'ReverseRepo', 'USDGBP', 'USDEUR', 'USDJPY', 'M1Supply', 'EmploymentRate', 'InflationRate', 'GDP', 'PCR', 'UMCSENT', 'Confidence', 'EFFR'\n",
    "    df = df.drop(columns=['future'])\n",
    "\n",
    "    output_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == 'SPYClose':\n",
    "            for number_of_days in [1, 2, 5, 21, 63]:\n",
    "                column_name = f'{col}{number_of_days}DayChange'\n",
    "                output_df = pd.concat([output_df, df[col].pct_change(number_of_days, fill_method='ffill').rename(column_name)], axis=1)\n",
    "                output_df.dropna(inplace=True)\n",
    "                output_df[column_name] = preprocessing.scale(output_df[column_name].values)\n",
    "                output_df[column_name] = output_df[column_name].clip(-3, 3) / 3\n",
    "        elif col in ['Volume', 'VIXClose', 'PCR', '1Mo', '3Mo', '1Yr', '2Yr', '5Yr', '10Yr', '20Yr', '30Yr', 'EFFR', 'Repo', 'RepoRate', 'ReverseRepo', 'ReverseRepoRate', 'Price', 'USDJPY', 'USDEUR', 'USDGBP']:\n",
    "            column_name = f'{col}DayChange'\n",
    "            output_df = pd.concat([output_df, df[col].pct_change(fill_method='ffill').rename(column_name)], axis=1)\n",
    "        elif col == 'M1Supply':\n",
    "            column_name = f'{col}WeekChange'\n",
    "            output_df = pd.concat([output_df, df[col].pct_change(7, fill_method='ffill').rename(column_name)], axis=1)\n",
    "        elif col in ['EmploymentRate', 'InflationRate', 'UMCSENT', 'Confidence']:\n",
    "            column_name = f'{col}MonthChange'\n",
    "            output_df = pd.concat([output_df, df[col].pct_change(24, fill_method='ffill').rename(column_name)], axis=1)\n",
    "        elif col == 'GDP':\n",
    "            column_name = f'{col}QuarterChange'\n",
    "            output_df = pd.concat([output_df, df[col].pct_change(65, fill_method='ffill').rename(column_name)], axis=1)\n",
    "        elif col == 'target':\n",
    "            output_df[col] = df[col]\n",
    "\n",
    "        if col not in ['SPYClose', 'target']:\n",
    "            output_df.dropna(inplace=True)\n",
    "            output_df[column_name] = preprocessing.scale(output_df[column_name].values)\n",
    "            output_df[column_name] = output_df[column_name].clip(-3, 3) / 3\n",
    "\n",
    "    output_df.dropna(inplace=True)\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "    \n",
    "    for i in output_df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 21 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "            \n",
    "    np.random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "    ups = []\n",
    "    downs = []\n",
    "\n",
    "    for sequence, target in sequential_data:    \n",
    "        if target == 0:\n",
    "            downs.append([sequence, target])\n",
    "        elif target == 1:\n",
    "            ups.append([sequence, target])\n",
    "    np.random.shuffle(ups)\n",
    "    np.random.shuffle(downs)\n",
    "\n",
    "    ## Get the value of the array with the smallest length\n",
    "    ## So we can ensure the training process is unbiased\n",
    "    ## As there will be 50:50 of up days and down days.\n",
    "    ## The model has to LEARN rather than REMEMBER\n",
    "    lower = min(len(ups), len(downs))\n",
    "\n",
    "    ups = ups[:lower]\n",
    "    downs = downs[:lower]\n",
    "\n",
    "    sequential_data = ups + downs\n",
    "\n",
    "    np.random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for sequence, target in sequential_data:\n",
    "        X.append(sequence)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply preprocessing, arrange data (training, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for next day's closing price\n",
    "combined_df['future'] = combined_df['SPYClose'].shift(-1)\n",
    "# Add column to signify if next day's closing price is up (1) or down (0) using classify\n",
    "# function defined above\n",
    "combined_df['target'] = list(map(classify, combined_df['SPYClose'], combined_df['future']))\n",
    "\n",
    "\n",
    "times = sorted(combined_df.index.values)\n",
    "last_20pct = sorted(combined_df.index.values)[-int(0.2*len(times))]  # get the last 20% of the times\n",
    "\n",
    "## Split in sample / out of sample\n",
    "validation_df = combined_df[(combined_df.index >= last_20pct)]  # make the validation data where the index is in the last 20%\n",
    "training_df = combined_df[(combined_df.index < last_20pct)]  # now the combined_df is all the data up to the last 20%\n",
    "\n",
    "train_x, train_y = preprocess_df(training_df)\n",
    "validation_x, validation_y = preprocess_df(validation_df)\n",
    "\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {np.count_nonzero(train_y == 0)}, buys: {np.count_nonzero(train_y == 1)}\")\n",
    "print(f\"VALIDATION Dont buys: {np.count_nonzero(validation_y == 0)}, buys: {np.count_nonzero(validation_y == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, BatchNormalization, Dense, Conv1D, MaxPooling1D, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract specific number of days for training from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_days(number_of_days, x):\n",
    "    return np.delete(x, np.s_[:-number_of_days], 1)\n",
    "\n",
    "# Use 21 days for initial tests\n",
    "initial_train_x = get_last_days(21, train_x)\n",
    "initial_validation_x = get_last_days(21, validation_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 1 - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_1():\n",
    "    time_at_start = int(time())\n",
    "    lstm_layers = [1, 2]\n",
    "    dense_layers = [2, 3]\n",
    "    lstm_layer_sizes = [32, 64]\n",
    "    dense_layer_sizes = [32, 64]\n",
    "\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        for dense_layer_size in dense_layer_sizes:\n",
    "            for lstm_layer in lstm_layers:\n",
    "                for lstm_layer_size in lstm_layer_sizes:\n",
    "                    name = f\"{lstm_layer}LSTM{lstm_layer_size}-{dense_layer}DENSE{dense_layer_size}-{int(time())}\"\n",
    "\n",
    "                    model = Sequential()\n",
    "                    model.add(Input(shape=(initial_train_x.shape[1:])))\n",
    "\n",
    "                    for layer in range(lstm_layer - 1):            \n",
    "                        model.add(LSTM(lstm_layer_size, return_sequences=True))\n",
    "                        model.add(Dropout(0.4))\n",
    "                        model.add(BatchNormalization())\n",
    "\n",
    "                    model.add(LSTM(lstm_layer_size))\n",
    "                    model.add(Dropout(0.4))\n",
    "                    model.add(BatchNormalization())\n",
    "\n",
    "                    for layer in range(dense_layer - 1):\n",
    "                        model.add(Dense(dense_layer_size, activation='relu'))\n",
    "                        model.add(Dropout(0.4))\n",
    "\n",
    "                    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "                    opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "                    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                                    optimizer=opt,\n",
    "                                    metrics=['accuracy'])\n",
    "\n",
    "                    tensorboard = TensorBoard(log_dir=f'lstmiteration1logs-{time_at_start}/{name}')\n",
    "\n",
    "                    checkpoint_filepath = f\"lstmiteration1models-{time_at_start}/\" + name + \"-{epoch:02d}-{val_accuracy:.3f}.hd5\"\n",
    "                    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "                    early_stopping = EarlyStopping(monitor='val_accuracy', baseline=0.5, patience=12)\n",
    "\n",
    "                    history = model.fit(\n",
    "                        initial_train_x, train_y,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(initial_validation_x, validation_y),\n",
    "                        callbacks=[tensorboard, checkpoint, early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last(x):\n",
    "    return x[-1]\n",
    "\n",
    "number_of_features = train_x.shape[-1]\n",
    "cnn_train_x = get_last_days(1, train_x)\n",
    "cnn_validation_x = get_last_days(1, validation_x)\n",
    "\n",
    "def iteration_2():\n",
    "    time_at_start = int(time())\n",
    "    conv_layers = [1, 2]\n",
    "    conv_layer_sizes = [16, 32]\n",
    "    dense_layers = [1, 2]\n",
    "    dense_layer_sizes = [32, 64]\n",
    "\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        for dense_layer_size in dense_layer_sizes:\n",
    "                    for conv_layer in conv_layers:\n",
    "                        for conv_layer_size in conv_layer_sizes:\n",
    "                            name = f\"{conv_layer}C{conv_layer_size}-{dense_layer}D{dense_layer_size}-{int(time())}\"\n",
    "\n",
    "                            model = Sequential()\n",
    "                            model.add(Input(shape=(cnn_train_x.shape[1:])))\n",
    "\n",
    "                            for layer in range(conv_layer - 1):\n",
    "                                model.add(Conv1D(conv_layer_size, kernel_size=1, padding='valid', activation='relu'))\n",
    "                                model.add(MaxPooling1D(1))\n",
    "                    \n",
    "                            model.add(Conv1D(conv_layer_size, kernel_size=1, padding='valid', activation='relu'))\n",
    "                            model.add(MaxPooling1D(1))\n",
    "\n",
    "                            model.add(Flatten())\n",
    "\n",
    "                            for layer in range(dense_layer - 1):\n",
    "                                model.add(Dense(dense_layer_size, activation='relu'))\n",
    "                                model.add(Dropout(0.4))\n",
    "\n",
    "                            model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "                            opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "                            model.compile(loss='sparse_categorical_crossentropy',\n",
    "                                            optimizer=opt,\n",
    "                                            metrics=['accuracy'])\n",
    "\n",
    "                            tensorboard = TensorBoard(log_dir=f'cnniteration2logs-{time_at_start}/{name}')\n",
    "\n",
    "                            checkpoint_filepath = f\"cnniteration2models-{time_at_start}/\" + name + \"-{epoch:02d}-{val_accuracy:.3f}.hd5\"\n",
    "                            checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "                            early_stopping = EarlyStopping(monitor='val_accuracy', baseline=0.5, patience=12)\n",
    "\n",
    "                            history = model.fit(\n",
    "                                cnn_train_x, train_y,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                validation_data=(cnn_validation_x, validation_y),\n",
    "                                callbacks=[tensorboard, checkpoint, early_stopping]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 3 - CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_3():\n",
    "    time_at_start = int(time())\n",
    "    conv_layers = [1,2]\n",
    "    conv_layer_sizes = [16, 32]\n",
    "    lstm_layers = [1,2]\n",
    "    dense_layers = [2,3]\n",
    "    lstm_layer_sizes = [16, 32]\n",
    "    dense_layer_sizes = [32, 64]\n",
    "\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        for dense_layer_size in dense_layer_sizes:\n",
    "            for lstm_layer in lstm_layers:\n",
    "                for lstm_layer_size in lstm_layer_sizes:\n",
    "                    for conv_layer in conv_layers:\n",
    "                        for conv_layer_size in conv_layer_sizes:\n",
    "                            name = f\"{conv_layer}C{conv_layer_size}-{lstm_layer}L{lstm_layer_size}-{dense_layer}D{dense_layer_size}-{int(time())}\"\n",
    "\n",
    "                            model = Sequential()\n",
    "                            model.add(Input(shape=(initial_train_x.shape[1:])))\n",
    "                            \n",
    "                            for layer in range(conv_layer - 1):            \n",
    "                                model.add(Conv1D(conv_layer_size, 2, padding='same'))\n",
    "                                \n",
    "                            model.add(Conv1D(conv_layer_size, 2, padding='same'))\n",
    "\n",
    "                            for layer in range(lstm_layer - 1):            \n",
    "                                model.add(LSTM(lstm_layer_size, return_sequences=True))\n",
    "                                model.add(Dropout(0.4))\n",
    "                                model.add(BatchNormalization())\n",
    "\n",
    "                            model.add(LSTM(lstm_layer_size))\n",
    "                            model.add(Dropout(0.4))\n",
    "                            model.add(BatchNormalization())\n",
    "\n",
    "                            for layer in range(dense_layer - 1):\n",
    "                                model.add(Dense(dense_layer_size, activation='relu'))\n",
    "                                model.add(Dropout(0.4))\n",
    "\n",
    "                            model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "                            opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "                            model.compile(loss='sparse_categorical_crossentropy',\n",
    "                                            optimizer=opt,\n",
    "                                            metrics=['accuracy'])\n",
    "\n",
    "                            tensorboard = TensorBoard(log_dir=f'cnnlstmiteration3logs-{time_at_start}/{name}')\n",
    "\n",
    "                            checkpoint_filepath = f\"cnnlstmiteration3models-{time_at_start}/\" + name + \"-{epoch:02d}-{val_accuracy:.3f}.hd5\"\n",
    "                            checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "                            early_stopping = EarlyStopping(monitor='val_accuracy', baseline=0.5, patience=12)\n",
    "\n",
    "                            history = model.fit(\n",
    "                                initial_train_x, train_y,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                validation_data=(initial_validation_x, validation_y),\n",
    "                                callbacks=[tensorboard, checkpoint, early_stopping]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 4 - LSTM + CNN + CNNLSTM (concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_4():\n",
    "    # LSTM\n",
    "    lstm_input = Input(shape=(initial_train_x.shape[1:]))\n",
    "        \n",
    "    lstm_lstm_1 = LSTM(64, return_sequences=True)(lstm_input)\n",
    "    lstm_dropout_1 = Dropout(0.4)(lstm_lstm_1)\n",
    "    lstm_bn_1 = BatchNormalization()(lstm_dropout_1)\n",
    "\n",
    "    lstm_lstm_2 = LSTM(64)(lstm_bn_1)\n",
    "    lstm_dropout_2 = Dropout(0.4)(lstm_lstm_2)\n",
    "    lstm_bn_2 = BatchNormalization()(lstm_dropout_2)\n",
    "\n",
    "    lstm_dense_1 = Dense(32, activation='relu')(lstm_bn_2)\n",
    "    lstm_dropout_3 = Dropout(0.4)(lstm_dense_1)\n",
    "\n",
    "    # # lstm_dense_3 = Dense(2, activation='softmax')(lstm_dropout_3)\n",
    "\n",
    "    # CNN\n",
    "    cnn_input = Input(shape=(cnn_train_x.shape[1:]))\n",
    "\n",
    "    cnn_conv_1 = Conv1D(32, kernel_size=1, padding='valid', activation='relu')(cnn_input)\n",
    "    cnn_pool_1 = MaxPooling1D(1)(cnn_conv_1)\n",
    "    cnn_flat_1 = Flatten()(cnn_pool_1)\n",
    "\n",
    "    # # cnn_dense_1 = Dense(2, activation='softmax')(cnn_flat_1)\n",
    "\n",
    "    # CNN LSTM\n",
    "    cnn_lstm_input = Input(shape=(initial_train_x.shape[1:]))\n",
    "                    \n",
    "    cnn_lstm_conv_1 = Conv1D(32, 2, padding='same')(cnn_lstm_input)\n",
    "    cnn_lstm_conv_2 = Conv1D(32, 2, padding='same')(cnn_lstm_conv_1)\n",
    "\n",
    "    cnn_lstm_lstm_1 = LSTM(16)(cnn_lstm_conv_2)\n",
    "    cnn_lstm_drop_1 = Dropout(0.4)(cnn_lstm_lstm_1)\n",
    "    cnn_lstm_bn_1 = BatchNormalization()(cnn_lstm_drop_1)\n",
    "\n",
    "    cnn_lstm_dense_1 = Dense(64, activation='relu')(cnn_lstm_bn_1)\n",
    "    cnn_lstm_drop_2 = Dropout(0.4)(cnn_lstm_dense_1)\n",
    "\n",
    "    # # cnn_lstm_dense_2 = Dense(2, activation='softmax')(cnn_lstm_drop_2)\n",
    "\n",
    "    concat = Concatenate()([lstm_dropout_3, cnn_flat_1, cnn_lstm_drop_2])\n",
    "    final_dense_1 = Dense(32, activation='relu')(concat)\n",
    "    output = Dense(2, activation='softmax')(final_dense_1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[lstm_input, cnn_input, cnn_lstm_input], outputs=[output])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                    optimizer=opt,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=f'ensemble1logs-{int(time())}/Ensemble-Model')\n",
    "\n",
    "    checkpoint_filepath = f\"ensemble1models-{int(time())}\" + \"/Ensemble-Model-{epoch:02d}-{val_accuracy:.3f}.hd5\"\n",
    "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', baseline=0.5, patience=12)\n",
    "\n",
    "    history = model.fit(\n",
    "        [initial_train_x, cnn_train_x, initial_train_x], train_y,\n",
    "        batch_size=32,\n",
    "        epochs=30,\n",
    "        validation_data=([initial_validation_x, cnn_validation_x, initial_validation_x], validation_y),\n",
    "        callbacks=[tensorboard, checkpoint, early_stopping]\n",
    "    )\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 5 - Sequence Lengths + Input Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_two_days = get_last_days(2, train_x) # 2 days\n",
    "train_x_week = get_last_days(5, train_x) # 1 week\n",
    "train_x_month = get_last_days(21, train_x) # 1 month\n",
    "train_x # 1 quarter\n",
    "\n",
    "validation_x_two_days = get_last_days(2, validation_x) # 2 days\n",
    "validation_x_week = get_last_days(5, validation_x) # 1 week\n",
    "validation_x_month = get_last_days(21, validation_x) # 1 month\n",
    "validation_x # 1 quarter\n",
    "\n",
    "def extract_columns(columns_array, x):\n",
    "    return x[:,:,columns_array]\n",
    "\n",
    "def iteration_5_model(name, time_at_start, train_inputs, validation_inputs):\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 50\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train_inputs.shape[1:])))\n",
    "        \n",
    "    model.add(Conv1D(32, 2, padding='same'))\n",
    "    model.add(Conv1D(32, 2, padding='same'))\n",
    "\n",
    "    model.add(LSTM(16))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                    optimizer=opt,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=f'cnnlstmiteration5logs-{time_at_start}/{name}')\n",
    "\n",
    "    checkpoint_filepath = f\"cnnlstmiteration5models-{time_at_start}/\" + name + \"-{epoch:02d}-{val_accuracy:.3f}.hd5\"\n",
    "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', baseline=0.5, patience=12)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_inputs, train_y,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(validation_inputs, validation_y),\n",
    "        callbacks=[tensorboard, checkpoint, early_stopping]\n",
    "    )\n",
    "\n",
    "def iteration_5():\n",
    "    time_at_start = int(time())\n",
    "\n",
    "    for training_set in ['two_days', 'week', 'month', 'quarter']:\n",
    "        if training_set == 'two_days':\n",
    "            training_set_to_use = train_x_two_days\n",
    "            validation_set_to_use = validation_x_two_days\n",
    "        elif training_set == 'week':\n",
    "            training_set_to_use = train_x_week\n",
    "            validation_set_to_use = validation_x_week\n",
    "        elif training_set == 'month':\n",
    "            training_set_to_use = train_x_month\n",
    "            validation_set_to_use = validation_x_month\n",
    "        elif training_set == 'quarter':\n",
    "            training_set_to_use = train_x\n",
    "            validation_set_to_use = validation_x\n",
    "        for input_features in ['price_only', 'price_extended_and_volume_and_volatility',\n",
    "        'price_and_money_supply_and_gdp', 'price_and_treasury_yields',\n",
    "        'price_and_effr_and_repo', 'price_and_gold_and_currency', 'price_and_options',\n",
    "        'price_and_inflation', 'price_and_employment', 'price_and_other_sentiment']:\n",
    "            if input_features == 'price_only':\n",
    "                train_inputs = extract_columns([0], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0], validation_set_to_use)\n",
    "            elif input_features == 'price_extended_and_volume_and_volatility':\n",
    "                train_inputs = extract_columns([0, 1, 2, 3, 4, 5, 6], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 1, 2, 3, 4, 5, 6], validation_set_to_use)\n",
    "            elif input_features == 'price_and_money_supply_and_gdp':\n",
    "                train_inputs = extract_columns([0, 7, 8], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 7, 8], validation_set_to_use)\n",
    "            elif input_features == 'price_and_treasury_yields':\n",
    "                train_inputs = extract_columns([0, 14, 15, 16, 17, 17, 19, 20, 21], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 14, 15, 16, 17, 17, 19, 20, 21], validation_set_to_use)\n",
    "            elif input_features == 'price_and_effr_and_repo':\n",
    "                train_inputs = extract_columns([0, 22, 23, 24, 25, 26], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 22, 23, 24, 25, 26], validation_set_to_use)\n",
    "            elif input_features == 'price_and_gold_and_currency':\n",
    "                train_inputs = extract_columns([0, 27, 28, 29, 30], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 27, 28, 29, 30], validation_set_to_use)\n",
    "            elif input_features == 'price_and_options':\n",
    "                train_inputs = extract_columns([0, 11], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 11], validation_set_to_use)\n",
    "            elif input_features == 'price_and_inflation':\n",
    "                train_inputs = extract_columns([0, 9], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 9], validation_set_to_use)\n",
    "            elif input_features == 'price_and_employment':\n",
    "                train_inputs = extract_columns([0, 8], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 8], validation_set_to_use)\n",
    "            elif input_features == 'price_and_other_sentiment':\n",
    "                train_inputs = extract_columns([0, 12, 13], training_set_to_use)\n",
    "                validation_inputs = extract_columns([0, 12, 13], validation_set_to_use)\n",
    "            \n",
    "            name = f\"{training_set}-{input_features}-{int(time())}\"\n",
    "            iteration_5_model(name, time_at_start, train_inputs, validation_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_255_layer_call_fn, lstm_cell_255_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_treasury_yields-1652765879-05-0.516.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_treasury_yields-1652765879-05-0.516.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F4FD00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 44ms/step - loss: 0.7017 - accuracy: 0.5088 - val_loss: 0.6929 - val_accuracy: 0.5161\n",
      "Epoch 6/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6977 - accuracy: 0.5070\n",
      "Epoch 6: val_accuracy did not improve from 0.51607\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6977 - accuracy: 0.5070 - val_loss: 0.6922 - val_accuracy: 0.5018\n",
      "Epoch 7/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.7016 - accuracy: 0.4992\n",
      "Epoch 7: val_accuracy did not improve from 0.51607\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7025 - accuracy: 0.4956 - val_loss: 0.6906 - val_accuracy: 0.5071\n",
      "Epoch 8/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6972 - accuracy: 0.5040\n",
      "Epoch 8: val_accuracy did not improve from 0.51607\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6971 - accuracy: 0.5040 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 9/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6974 - accuracy: 0.4942\n",
      "Epoch 9: val_accuracy did not improve from 0.51607\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6971 - accuracy: 0.4945 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6961 - accuracy: 0.5100\n",
      "Epoch 10: val_accuracy improved from 0.51607 to 0.52857, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_treasury_yields-1652765879-10-0.529.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_255_layer_call_fn, lstm_cell_255_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_treasury_yields-1652765879-10-0.529.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_treasury_yields-1652765879-10-0.529.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F4FD00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 3s 39ms/step - loss: 0.6954 - accuracy: 0.5132 - val_loss: 0.6918 - val_accuracy: 0.5286\n",
      "Epoch 11/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6974 - accuracy: 0.5158\n",
      "Epoch 11: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6974 - accuracy: 0.5158 - val_loss: 0.6911 - val_accuracy: 0.4893\n",
      "Epoch 12/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6975 - accuracy: 0.4965\n",
      "Epoch 12: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6981 - accuracy: 0.4941 - val_loss: 0.6897 - val_accuracy: 0.4964\n",
      "Epoch 13/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6936 - accuracy: 0.5081\n",
      "Epoch 13: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6935 - accuracy: 0.5106 - val_loss: 0.6911 - val_accuracy: 0.5179\n",
      "Epoch 14/50\n",
      "80/86 [==========================>...] - ETA: 0s - loss: 0.6952 - accuracy: 0.4949\n",
      "Epoch 14: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.4934 - val_loss: 0.6904 - val_accuracy: 0.4946\n",
      "Epoch 15/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.5207\n",
      "Epoch 15: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6923 - accuracy: 0.5212 - val_loss: 0.6906 - val_accuracy: 0.5036\n",
      "Epoch 16/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6939 - accuracy: 0.5179\n",
      "Epoch 16: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6936 - accuracy: 0.5179 - val_loss: 0.6903 - val_accuracy: 0.4964\n",
      "Epoch 17/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.5236\n",
      "Epoch 17: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6918 - accuracy: 0.5231 - val_loss: 0.6904 - val_accuracy: 0.5125\n",
      "Epoch 18/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.5004\n",
      "Epoch 18: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6959 - accuracy: 0.5007 - val_loss: 0.6909 - val_accuracy: 0.5089\n",
      "Epoch 19/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.5089\n",
      "Epoch 19: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5077 - val_loss: 0.6918 - val_accuracy: 0.5179\n",
      "Epoch 20/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6947 - accuracy: 0.5167\n",
      "Epoch 20: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6950 - accuracy: 0.5143 - val_loss: 0.6905 - val_accuracy: 0.4929\n",
      "Epoch 21/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6955 - accuracy: 0.5162\n",
      "Epoch 21: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6955 - accuracy: 0.5165 - val_loss: 0.6903 - val_accuracy: 0.5196\n",
      "Epoch 22/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5195\n",
      "Epoch 22: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6930 - accuracy: 0.5201 - val_loss: 0.6907 - val_accuracy: 0.5054\n",
      "Epoch 1/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7360 - accuracy: 0.4894\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-01-0.500.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_256_layer_call_fn, lstm_cell_256_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-01-0.500.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-01-0.500.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C285C9AEC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 5s 44ms/step - loss: 0.7360 - accuracy: 0.4894 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.7141 - accuracy: 0.4966\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7140 - accuracy: 0.4967 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7071 - accuracy: 0.5119\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7072 - accuracy: 0.5117 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "80/86 [==========================>...] - ETA: 0s - loss: 0.7011 - accuracy: 0.5094\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.7008 - accuracy: 0.5106 - val_loss: 0.6934 - val_accuracy: 0.4929\n",
      "Epoch 5/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.7024 - accuracy: 0.4959\n",
      "Epoch 5: val_accuracy improved from 0.50000 to 0.50536, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-05-0.505.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_256_layer_call_fn, lstm_cell_256_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-05-0.505.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-05-0.505.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C285C9AEC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 3s 40ms/step - loss: 0.7023 - accuracy: 0.4952 - val_loss: 0.6934 - val_accuracy: 0.5054\n",
      "Epoch 6/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.7018 - accuracy: 0.4811\n",
      "Epoch 6: val_accuracy did not improve from 0.50536\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7024 - accuracy: 0.4795 - val_loss: 0.6931 - val_accuracy: 0.4964\n",
      "Epoch 7/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6985 - accuracy: 0.4872\n",
      "Epoch 7: val_accuracy did not improve from 0.50536\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6981 - accuracy: 0.4905 - val_loss: 0.6938 - val_accuracy: 0.4929\n",
      "Epoch 8/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.7000 - accuracy: 0.4896\n",
      "Epoch 8: val_accuracy improved from 0.50536 to 0.51786, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-08-0.518.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_256_layer_call_fn, lstm_cell_256_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-08-0.518.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-08-0.518.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C285C9AEC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 41ms/step - loss: 0.6999 - accuracy: 0.4897 - val_loss: 0.6928 - val_accuracy: 0.5179\n",
      "Epoch 9/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.5123\n",
      "Epoch 9: val_accuracy improved from 0.51786 to 0.52857, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-09-0.529.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_256_layer_call_fn, lstm_cell_256_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-09-0.529.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_effr_and_repo-1652765910-09-0.529.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C285C9AEC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 45ms/step - loss: 0.6953 - accuracy: 0.5092 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
      "Epoch 10/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5066\n",
      "Epoch 10: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6960 - accuracy: 0.5066 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6968 - accuracy: 0.5026\n",
      "Epoch 11: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6969 - accuracy: 0.5004 - val_loss: 0.6918 - val_accuracy: 0.4929\n",
      "Epoch 12/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6957 - accuracy: 0.4947\n",
      "Epoch 12: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6961 - accuracy: 0.4927 - val_loss: 0.6917 - val_accuracy: 0.5089\n",
      "Epoch 13/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.4970\n",
      "Epoch 13: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6967 - accuracy: 0.4967 - val_loss: 0.6917 - val_accuracy: 0.5161\n",
      "Epoch 14/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6943 - accuracy: 0.5039\n",
      "Epoch 14: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6947 - accuracy: 0.4996 - val_loss: 0.6916 - val_accuracy: 0.5286\n",
      "Epoch 15/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6963 - accuracy: 0.4974\n",
      "Epoch 15: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6965 - accuracy: 0.4960 - val_loss: 0.6927 - val_accuracy: 0.5089\n",
      "Epoch 16/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5040\n",
      "Epoch 16: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6939 - accuracy: 0.5040 - val_loss: 0.6935 - val_accuracy: 0.4804\n",
      "Epoch 17/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.4971\n",
      "Epoch 17: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.4971 - val_loss: 0.6936 - val_accuracy: 0.4679\n",
      "Epoch 18/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6959 - accuracy: 0.4933\n",
      "Epoch 18: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6961 - accuracy: 0.4916 - val_loss: 0.6926 - val_accuracy: 0.5196\n",
      "Epoch 19/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5154\n",
      "Epoch 19: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6927 - accuracy: 0.5154 - val_loss: 0.6916 - val_accuracy: 0.5107\n",
      "Epoch 20/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.4989\n",
      "Epoch 20: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6945 - accuracy: 0.4989 - val_loss: 0.6915 - val_accuracy: 0.5054\n",
      "Epoch 21/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6954 - accuracy: 0.5007\n",
      "Epoch 21: val_accuracy did not improve from 0.52857\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6954 - accuracy: 0.5011 - val_loss: 0.6928 - val_accuracy: 0.5054\n",
      "Epoch 1/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.7413 - accuracy: 0.4985\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-01-0.500.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_257_layer_call_fn, lstm_cell_257_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-01-0.500.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-01-0.500.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C2028A38B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 6s 57ms/step - loss: 0.7411 - accuracy: 0.4989 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7247 - accuracy: 0.4919\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.7247 - accuracy: 0.4919 - val_loss: 0.6935 - val_accuracy: 0.4982\n",
      "Epoch 3/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.7145 - accuracy: 0.4897\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.7140 - accuracy: 0.4905 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.7043 - accuracy: 0.5057\n",
      "Epoch 4: val_accuracy improved from 0.50000 to 0.51429, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-04-0.514.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_257_layer_call_fn, lstm_cell_257_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-04-0.514.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-04-0.514.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C2028A38B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 43ms/step - loss: 0.7042 - accuracy: 0.5073 - val_loss: 0.6935 - val_accuracy: 0.5143\n",
      "Epoch 5/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.5183\n",
      "Epoch 5: val_accuracy did not improve from 0.51429\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7007 - accuracy: 0.5183 - val_loss: 0.6946 - val_accuracy: 0.5125\n",
      "Epoch 6/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.7049 - accuracy: 0.4949\n",
      "Epoch 6: val_accuracy did not improve from 0.51429\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7047 - accuracy: 0.4956 - val_loss: 0.6956 - val_accuracy: 0.4768\n",
      "Epoch 7/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6954 - accuracy: 0.5132\n",
      "Epoch 7: val_accuracy improved from 0.51429 to 0.52500, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-07-0.525.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_257_layer_call_fn, lstm_cell_257_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-07-0.525.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_gold_and_currency-1652765941-07-0.525.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C2028A38B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 43ms/step - loss: 0.6953 - accuracy: 0.5132 - val_loss: 0.6933 - val_accuracy: 0.5250\n",
      "Epoch 8/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.7003 - accuracy: 0.4882\n",
      "Epoch 8: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7001 - accuracy: 0.4883 - val_loss: 0.6930 - val_accuracy: 0.5018\n",
      "Epoch 9/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.5048\n",
      "Epoch 9: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6957 - accuracy: 0.5040 - val_loss: 0.6939 - val_accuracy: 0.5018\n",
      "Epoch 10/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.5114\n",
      "Epoch 10: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6964 - accuracy: 0.5084 - val_loss: 0.6946 - val_accuracy: 0.4786\n",
      "Epoch 11/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6947 - accuracy: 0.5147\n",
      "Epoch 11: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6948 - accuracy: 0.5147 - val_loss: 0.6965 - val_accuracy: 0.4661\n",
      "Epoch 12/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6937 - accuracy: 0.5164\n",
      "Epoch 12: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.5198 - val_loss: 0.6956 - val_accuracy: 0.4929\n",
      "Epoch 13/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7002 - accuracy: 0.4993\n",
      "Epoch 13: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6997 - accuracy: 0.5007 - val_loss: 0.6933 - val_accuracy: 0.5089\n",
      "Epoch 14/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.5022\n",
      "Epoch 14: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6965 - accuracy: 0.5026 - val_loss: 0.6943 - val_accuracy: 0.4911\n",
      "Epoch 15/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.5298\n",
      "Epoch 15: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6925 - accuracy: 0.5286 - val_loss: 0.6948 - val_accuracy: 0.4875\n",
      "Epoch 16/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5044\n",
      "Epoch 16: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6935 - accuracy: 0.5044 - val_loss: 0.6954 - val_accuracy: 0.4911\n",
      "Epoch 17/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5151\n",
      "Epoch 17: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6929 - accuracy: 0.5158 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "80/86 [==========================>...] - ETA: 0s - loss: 0.6935 - accuracy: 0.5133\n",
      "Epoch 18: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6928 - accuracy: 0.5128 - val_loss: 0.6942 - val_accuracy: 0.5071\n",
      "Epoch 19/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6903 - accuracy: 0.5173\n",
      "Epoch 19: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6902 - accuracy: 0.5201 - val_loss: 0.6974 - val_accuracy: 0.4804\n",
      "Epoch 1/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7171 - accuracy: 0.5071\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_options-1652765969-01-0.500.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_258_layer_call_fn, lstm_cell_258_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_options-1652765969-01-0.500.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_options-1652765969-01-0.500.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C29D4CC700> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 5s 48ms/step - loss: 0.7181 - accuracy: 0.5062 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.7060 - accuracy: 0.5072\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7052 - accuracy: 0.5103 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.4872\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7050 - accuracy: 0.4872 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.4923\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7025 - accuracy: 0.4923 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.4791\n",
      "Epoch 5: val_accuracy improved from 0.50000 to 0.52143, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_options-1652765969-05-0.521.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_258_layer_call_fn, lstm_cell_258_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_options-1652765969-05-0.521.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_options-1652765969-05-0.521.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C29D4CC700> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 44ms/step - loss: 0.7007 - accuracy: 0.4791 - val_loss: 0.6928 - val_accuracy: 0.5214\n",
      "Epoch 6/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6994 - accuracy: 0.4985\n",
      "Epoch 6: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6993 - accuracy: 0.4989 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6979 - accuracy: 0.4926\n",
      "Epoch 7: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6979 - accuracy: 0.4927 - val_loss: 0.6936 - val_accuracy: 0.5018\n",
      "Epoch 8/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.5070\n",
      "Epoch 8: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6944 - accuracy: 0.5073 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6975 - accuracy: 0.4956\n",
      "Epoch 9: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6975 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 10/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.4901\n",
      "Epoch 10: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6963 - accuracy: 0.4901 - val_loss: 0.6948 - val_accuracy: 0.5054\n",
      "Epoch 11/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.4974\n",
      "Epoch 11: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6965 - accuracy: 0.4974 - val_loss: 0.6921 - val_accuracy: 0.5089\n",
      "Epoch 12/50\n",
      "80/86 [==========================>...] - ETA: 0s - loss: 0.6958 - accuracy: 0.5113\n",
      "Epoch 12: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6963 - accuracy: 0.5040 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 13/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5108\n",
      "Epoch 13: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6936 - accuracy: 0.5110 - val_loss: 0.6934 - val_accuracy: 0.5089\n",
      "Epoch 14/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6957 - accuracy: 0.5026\n",
      "Epoch 14: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6957 - accuracy: 0.5026 - val_loss: 0.6929 - val_accuracy: 0.4964\n",
      "Epoch 15/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6954 - accuracy: 0.5088\n",
      "Epoch 15: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6954 - accuracy: 0.5088 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 16/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6950 - accuracy: 0.5088\n",
      "Epoch 16: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6949 - accuracy: 0.5088 - val_loss: 0.6928 - val_accuracy: 0.5143\n",
      "Epoch 17/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.5074\n",
      "Epoch 17: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6946 - accuracy: 0.5070 - val_loss: 0.6925 - val_accuracy: 0.5161\n",
      "Epoch 1/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7368 - accuracy: 0.5156\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-01-0.500.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_259_layer_call_fn, lstm_cell_259_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-01-0.500.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-01-0.500.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F585B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 5s 49ms/step - loss: 0.7375 - accuracy: 0.5154 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.7267 - accuracy: 0.4901\n",
      "Epoch 2: val_accuracy improved from 0.50000 to 0.50357, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-02-0.504.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_259_layer_call_fn, lstm_cell_259_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-02-0.504.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-02-0.504.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F585B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 41ms/step - loss: 0.7270 - accuracy: 0.4897 - val_loss: 0.6936 - val_accuracy: 0.5036\n",
      "Epoch 3/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7188 - accuracy: 0.4842\n",
      "Epoch 3: val_accuracy did not improve from 0.50357\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.7188 - accuracy: 0.4842 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7008 - accuracy: 0.5134\n",
      "Epoch 4: val_accuracy did not improve from 0.50357\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7012 - accuracy: 0.5121 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.7076 - accuracy: 0.4974\n",
      "Epoch 5: val_accuracy improved from 0.50357 to 0.50536, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-05-0.505.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_259_layer_call_fn, lstm_cell_259_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-05-0.505.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-05-0.505.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F585B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 48ms/step - loss: 0.7077 - accuracy: 0.4967 - val_loss: 0.6937 - val_accuracy: 0.5054\n",
      "Epoch 6/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6997 - accuracy: 0.4929\n",
      "Epoch 6: val_accuracy did not improve from 0.50536\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.6997 - accuracy: 0.4945 - val_loss: 0.6940 - val_accuracy: 0.4929\n",
      "Epoch 7/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.4927\n",
      "Epoch 7: val_accuracy improved from 0.50536 to 0.51429, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-07-0.514.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_259_layer_call_fn, lstm_cell_259_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-07-0.514.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-07-0.514.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F585B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 48ms/step - loss: 0.7041 - accuracy: 0.4927 - val_loss: 0.6964 - val_accuracy: 0.5143\n",
      "Epoch 8/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6999 - accuracy: 0.5007\n",
      "Epoch 8: val_accuracy improved from 0.51429 to 0.51964, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-08-0.520.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_259_layer_call_fn, lstm_cell_259_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-08-0.520.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-08-0.520.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F585B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 41ms/step - loss: 0.6999 - accuracy: 0.5000 - val_loss: 0.6953 - val_accuracy: 0.5196\n",
      "Epoch 9/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6971 - accuracy: 0.5018\n",
      "Epoch 9: val_accuracy did not improve from 0.51964\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6971 - accuracy: 0.5015 - val_loss: 0.6958 - val_accuracy: 0.5018\n",
      "Epoch 10/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.4956\n",
      "Epoch 10: val_accuracy did not improve from 0.51964\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6995 - accuracy: 0.4956 - val_loss: 0.6936 - val_accuracy: 0.5054\n",
      "Epoch 11/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.5134\n",
      "Epoch 11: val_accuracy did not improve from 0.51964\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6961 - accuracy: 0.5110 - val_loss: 0.6941 - val_accuracy: 0.4982\n",
      "Epoch 12/50\n",
      "80/86 [==========================>...] - ETA: 0s - loss: 0.6950 - accuracy: 0.5180\n",
      "Epoch 12: val_accuracy did not improve from 0.51964\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6954 - accuracy: 0.5179 - val_loss: 0.6950 - val_accuracy: 0.5196\n",
      "Epoch 13/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6944 - accuracy: 0.5150\n",
      "Epoch 13: val_accuracy did not improve from 0.51964\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6947 - accuracy: 0.5139 - val_loss: 0.6975 - val_accuracy: 0.4875\n",
      "Epoch 14/50\n",
      "80/86 [==========================>...] - ETA: 0s - loss: 0.6967 - accuracy: 0.4930\n",
      "Epoch 14: val_accuracy did not improve from 0.51964\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6967 - accuracy: 0.4952 - val_loss: 0.6959 - val_accuracy: 0.4732\n",
      "Epoch 15/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5059\n",
      "Epoch 15: val_accuracy improved from 0.51964 to 0.52321, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-15-0.523.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_259_layer_call_fn, lstm_cell_259_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-15-0.523.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_inflation-1652765992-15-0.523.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1E4F585B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 42ms/step - loss: 0.6960 - accuracy: 0.5059 - val_loss: 0.6927 - val_accuracy: 0.5232\n",
      "Epoch 16/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.5015\n",
      "Epoch 16: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6978 - accuracy: 0.5015 - val_loss: 0.6967 - val_accuracy: 0.5018\n",
      "Epoch 17/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6952 - accuracy: 0.5060\n",
      "Epoch 17: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.5059 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6944 - accuracy: 0.4996\n",
      "Epoch 18: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6946 - accuracy: 0.4985 - val_loss: 0.6954 - val_accuracy: 0.5036\n",
      "Epoch 19/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6920 - accuracy: 0.5122\n",
      "Epoch 19: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6925 - accuracy: 0.5117 - val_loss: 0.6954 - val_accuracy: 0.4875\n",
      "Epoch 20/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.5026\n",
      "Epoch 20: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6944 - accuracy: 0.5029 - val_loss: 0.6951 - val_accuracy: 0.4804\n",
      "Epoch 21/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5044\n",
      "Epoch 21: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6934 - accuracy: 0.5040 - val_loss: 0.6948 - val_accuracy: 0.4821\n",
      "Epoch 22/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5195\n",
      "Epoch 22: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6927 - accuracy: 0.5187 - val_loss: 0.6937 - val_accuracy: 0.5089\n",
      "Epoch 23/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.5193\n",
      "Epoch 23: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6938 - accuracy: 0.5205 - val_loss: 0.6936 - val_accuracy: 0.4696\n",
      "Epoch 24/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5162\n",
      "Epoch 24: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6936 - accuracy: 0.5161 - val_loss: 0.6932 - val_accuracy: 0.5196\n",
      "Epoch 25/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.5004\n",
      "Epoch 25: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6947 - accuracy: 0.5007 - val_loss: 0.6941 - val_accuracy: 0.5089\n",
      "Epoch 26/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.4996\n",
      "Epoch 26: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.4989 - val_loss: 0.6937 - val_accuracy: 0.4946\n",
      "Epoch 27/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.5132\n",
      "Epoch 27: val_accuracy did not improve from 0.52321\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6926 - accuracy: 0.5128 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 1/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7354 - accuracy: 0.5018\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-01-0.500.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_260_layer_call_fn, lstm_cell_260_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-01-0.500.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-01-0.500.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C27BEA2EC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 6s 52ms/step - loss: 0.7354 - accuracy: 0.5018 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.7273 - accuracy: 0.4901\n",
      "Epoch 2: val_accuracy improved from 0.50000 to 0.50714, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-02-0.507.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_260_layer_call_fn, lstm_cell_260_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-02-0.507.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-02-0.507.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C27BEA2EC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 44ms/step - loss: 0.7274 - accuracy: 0.4901 - val_loss: 0.6934 - val_accuracy: 0.5071\n",
      "Epoch 3/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.4963\n",
      "Epoch 3: val_accuracy improved from 0.50714 to 0.52500, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-03-0.525.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_260_layer_call_fn, lstm_cell_260_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-03-0.525.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_employment-1652766036-03-0.525.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C27BEA2EC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 3s 41ms/step - loss: 0.7145 - accuracy: 0.4963 - val_loss: 0.6925 - val_accuracy: 0.5250\n",
      "Epoch 4/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.7074 - accuracy: 0.5008\n",
      "Epoch 4: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7065 - accuracy: 0.5033 - val_loss: 0.6927 - val_accuracy: 0.5143\n",
      "Epoch 5/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.7106 - accuracy: 0.4962\n",
      "Epoch 5: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7099 - accuracy: 0.4985 - val_loss: 0.6923 - val_accuracy: 0.5036\n",
      "Epoch 6/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.5125\n",
      "Epoch 6: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7035 - accuracy: 0.5125 - val_loss: 0.6924 - val_accuracy: 0.5018\n",
      "Epoch 7/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.7041 - accuracy: 0.5027\n",
      "Epoch 7: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.7030 - accuracy: 0.5066 - val_loss: 0.6935 - val_accuracy: 0.4625\n",
      "Epoch 8/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.7021 - accuracy: 0.4863\n",
      "Epoch 8: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7018 - accuracy: 0.4868 - val_loss: 0.6938 - val_accuracy: 0.4839\n",
      "Epoch 9/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.5194\n",
      "Epoch 9: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6990 - accuracy: 0.5194 - val_loss: 0.6937 - val_accuracy: 0.5036\n",
      "Epoch 10/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6954 - accuracy: 0.5110\n",
      "Epoch 10: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6954 - accuracy: 0.5110 - val_loss: 0.6950 - val_accuracy: 0.4893\n",
      "Epoch 11/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6972 - accuracy: 0.4977\n",
      "Epoch 11: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.6974 - accuracy: 0.4963 - val_loss: 0.6923 - val_accuracy: 0.5054\n",
      "Epoch 12/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6975 - accuracy: 0.4989\n",
      "Epoch 12: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.6974 - accuracy: 0.4993 - val_loss: 0.6927 - val_accuracy: 0.4857\n",
      "Epoch 13/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6978 - accuracy: 0.4989\n",
      "Epoch 13: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.6984 - accuracy: 0.4963 - val_loss: 0.6950 - val_accuracy: 0.4643\n",
      "Epoch 14/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.4993\n",
      "Epoch 14: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.6966 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.4625\n",
      "Epoch 15/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.5057\n",
      "Epoch 15: val_accuracy did not improve from 0.52500\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.6953 - accuracy: 0.5044 - val_loss: 0.6933 - val_accuracy: 0.4964\n",
      "Epoch 1/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.7570 - accuracy: 0.5079\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52143, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-01-0.521.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_261_layer_call_fn, lstm_cell_261_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-01-0.521.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-01-0.521.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C265148B80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 5s 50ms/step - loss: 0.7549 - accuracy: 0.5110 - val_loss: 0.6924 - val_accuracy: 0.5214\n",
      "Epoch 2/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.7311 - accuracy: 0.5057\n",
      "Epoch 2: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.7310 - accuracy: 0.5055 - val_loss: 0.6929 - val_accuracy: 0.5143\n",
      "Epoch 3/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7213 - accuracy: 0.4866\n",
      "Epoch 3: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.7218 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4911\n",
      "Epoch 4/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.7067 - accuracy: 0.5029\n",
      "Epoch 4: val_accuracy did not improve from 0.52143\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.7065 - accuracy: 0.5037 - val_loss: 0.6929 - val_accuracy: 0.5107\n",
      "Epoch 5/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7088 - accuracy: 0.5086\n",
      "Epoch 5: val_accuracy improved from 0.52143 to 0.53214, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-05-0.532.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_261_layer_call_fn, lstm_cell_261_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-05-0.532.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-05-0.532.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C265148B80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 4s 45ms/step - loss: 0.7092 - accuracy: 0.5081 - val_loss: 0.6925 - val_accuracy: 0.5321\n",
      "Epoch 6/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.7043 - accuracy: 0.5184\n",
      "Epoch 6: val_accuracy improved from 0.53214 to 0.53393, saving model to cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-06-0.534.hd5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_261_layer_call_fn, lstm_cell_261_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-06-0.534.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnnlstmiteration5models-1652764964\\quarter-price_and_other_sentiment-1652766061-06-0.534.hd5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C265148B80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 3s 41ms/step - loss: 0.7041 - accuracy: 0.5190 - val_loss: 0.6927 - val_accuracy: 0.5339\n",
      "Epoch 7/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.7011 - accuracy: 0.5160\n",
      "Epoch 7: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7014 - accuracy: 0.5136 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 8/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6999 - accuracy: 0.5141\n",
      "Epoch 8: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6998 - accuracy: 0.5136 - val_loss: 0.6934 - val_accuracy: 0.5125\n",
      "Epoch 9/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6995 - accuracy: 0.5130\n",
      "Epoch 9: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6992 - accuracy: 0.5136 - val_loss: 0.6939 - val_accuracy: 0.4821\n",
      "Epoch 10/50\n",
      "82/86 [===========================>..] - ETA: 0s - loss: 0.6944 - accuracy: 0.5221\n",
      "Epoch 10: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6947 - accuracy: 0.5198 - val_loss: 0.6940 - val_accuracy: 0.4857\n",
      "Epoch 11/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.5312\n",
      "Epoch 11: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6958 - accuracy: 0.5308 - val_loss: 0.6940 - val_accuracy: 0.5089\n",
      "Epoch 12/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6948 - accuracy: 0.5035\n",
      "Epoch 12: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.5015 - val_loss: 0.6952 - val_accuracy: 0.5179\n",
      "Epoch 13/50\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.5260\n",
      "Epoch 13: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6942 - accuracy: 0.5260 - val_loss: 0.6938 - val_accuracy: 0.5250\n",
      "Epoch 14/50\n",
      "81/86 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.5054\n",
      "Epoch 14: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.5073 - val_loss: 0.6941 - val_accuracy: 0.5304\n",
      "Epoch 15/50\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.5123\n",
      "Epoch 15: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.6947 - accuracy: 0.5110 - val_loss: 0.6935 - val_accuracy: 0.5125\n",
      "Epoch 16/50\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.5011\n",
      "Epoch 16: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6957 - accuracy: 0.5015 - val_loss: 0.6930 - val_accuracy: 0.5232\n",
      "Epoch 17/50\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5230\n",
      "Epoch 17: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6930 - accuracy: 0.5234 - val_loss: 0.6940 - val_accuracy: 0.4982\n",
      "Epoch 18/50\n",
      "80/86 [==========================>...] - ETA: 0s - loss: 0.6942 - accuracy: 0.5137\n",
      "Epoch 18: val_accuracy did not improve from 0.53393\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.6938 - accuracy: 0.5158 - val_loss: 0.6935 - val_accuracy: 0.5196\n"
     ]
    }
   ],
   "source": [
    "iteration_5()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
